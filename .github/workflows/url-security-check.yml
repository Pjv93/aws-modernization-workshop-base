name: URL Security Check

on:
  pull_request:
  push:
    branches: [ main, master ]
  schedule:
    # Run monthly on the 1st at 2 AM UTC
    - cron: '0 2 1 * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  url-security-scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Check URLs for inappropriate content
      run: |
        python3 << 'EOF'
        import re, subprocess, sys, requests, os
        from concurrent.futures import ThreadPoolExecutor

        def extract_urls_from_file(file_path):
            """Extract URLs with and without protocols from any file"""
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                    urls = set()
                    
                    # 1. Standard HTTP/HTTPS URLs
                    http_urls = re.findall(r'https?://[^\s<>"\'`\)]+', content)
                    urls.update(http_urls)
                    
                    # 2. Protocol-relative URLs (//example.com)
                    protocol_relative = re.findall(r'//[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}[^\s<>"\'`\)]*', content)
                    urls.update(['https:' + url for url in protocol_relative])
                    
                    # 3. Domain-only URLs (example.com, www.example.com)
                    domain_pattern = r'\b(?:www\.)?[a-zA-Z0-9-]+\.[a-zA-Z]{2,}(?:\.[a-zA-Z]{2,})?(?:/[^\s<>"\'`\)]*)?'
                    potential_domains = re.findall(domain_pattern, content)
                    
                    # Filter out common false positives
                    for domain in potential_domains:
                        if not any(skip in domain.lower() for skip in [
                            'localhost', '127.0.0.1', 'example.com', 'test.com',
                            '.js', '.css', '.json', '.xml', '.py', '.java',
                            'version.', 'config.', 'package.', 'github.com'
                        ]):
                            urls.add('https://' + domain)
                    
                    return list(urls)
            except:
                return []

        def extract_urls_from_diff():
            """Extract URLs from git diff (commit changes only)"""
            try:
                result = subprocess.run(['git', 'diff', 'HEAD~1', 'HEAD'], capture_output=True, text=True)
                urls = set()
                for line in result.stdout.split('\n'):
                    if line.startswith('+') and not line.startswith('+++'):
                        # Extract URLs from added lines using same comprehensive method
                        line_urls = extract_urls_from_content(line)
                        urls.update(line_urls)
                return list(urls)
            except: 
                return []

        def extract_urls_from_content(content):
            """Helper to extract URLs from a single content string"""
            urls = set()
            
            # Standard HTTP/HTTPS URLs
            http_urls = re.findall(r'https?://[^\s<>"\'`\)]+', content)
            urls.update(http_urls)
            
            # Protocol-relative URLs
            protocol_relative = re.findall(r'//[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}[^\s<>"\'`\)]*', content)
            urls.update(['https:' + url for url in protocol_relative])
            
            # Domain-only URLs
            domain_pattern = r'\b(?:www\.)?[a-zA-Z0-9-]+\.[a-zA-Z]{2,}(?:\.[a-zA-Z]{2,})?(?:/[^\s<>"\'`\)]*)?'
            potential_domains = re.findall(domain_pattern, content)
            
            for domain in potential_domains:
                if not any(skip in domain.lower() for skip in [
                    'localhost', '127.0.0.1', 'example.com', 'test.com',
                    '.js', '.css', '.json', '.xml', '.py', '.java',
                    'version.', 'config.', 'package.', 'github.com'
                ]):
                    urls.add('https://' + domain)
            
            return list(urls)

        def find_all_urls():
            """Scan all files for URLs (monthly scan)"""
            all_urls = set()
            # Scan all files except binary and dependency files
            for root, dirs, files in os.walk('.'):
                # Skip common directories
                dirs[:] = [d for d in dirs if d not in ['.git', 'node_modules', '__pycache__', '.venv']]
                
                for file in files:
                    # Skip binary files
                    if file.endswith(('.png', '.jpg', '.jpeg', '.gif', '.ico', '.svg', '.pdf', 
                                    '.zip', '.tar', '.gz', '.exe', '.bin', '.dll')):
                        continue
                    
                    file_path = os.path.join(root, file)
                    urls = extract_urls_from_file(file_path)
                    all_urls.update(urls)
            
            return list(all_urls)

        def check_url_content(url):
            """Check URL content for inappropriate material"""
            try:
                # Normalize URL
                if not url.startswith(('http://', 'https://')):
                    url = 'https://' + url
                
                # Try HEAD request first for efficiency
                response = requests.head(url, timeout=10, allow_redirects=True, 
                                       headers={'User-Agent': 'SecurityBot/1.0'})
                
                if response.status_code == 405:  # Method not allowed, try GET
                    response = requests.get(url, timeout=10, stream=True,
                                         headers={'User-Agent': 'SecurityBot/1.0'})
                    content = response.text[:2000]  # Only check first 2KB
                else:
                    content = ""
                
                # Combine URL and content for analysis
                full_content = f"{url} {content}".lower()
                
                # Broad indicators (any occurrence)
                broad_indicators = ['porn', 'xxx', 'sex', 'nude', 'erotic', 'nsfw', '18+', 'explicit', 'hardcore', 'webcam', 'escort', 'fetish']
                
                # Contextual patterns (more specific)
                adult_patterns = ['adult content', 'adult site', 'adult entertainment', 'adult videos', 'adult material', 'adult webcam']
                
                # Check broad indicators first
                for indicator in broad_indicators:
                    if indicator in full_content:
                        # Skip if it's legitimate educational context
                        if any(edu in full_content for edu in ['adult education', 'adult learning', 'continuing education']):
                            continue
                        return True, indicator
                
                # Check contextual patterns
                for pattern in adult_patterns:
                    if pattern in full_content:
                        return True, pattern
                
                return False, None
            except Exception as e:
                print(f"    ‚ö†Ô∏è  Could not check {url}: {str(e)}")
                return False, None

        # Determine scan type based on trigger
        if os.getenv('GITHUB_EVENT_NAME') == 'schedule':
            # Monthly full scan
            urls = find_all_urls()
            scan_type = "Monthly full repository scan"
        else:
            # Commit-based scan
            urls = extract_urls_from_diff()
            scan_type = "Commit diff scan"
        
        if not urls:
            print(f"‚úÖ {scan_type}: No URLs found")
            sys.exit(0)
        
        print(f"üîç {scan_type}: Found {len(urls)} URLs to check (with and without protocols)...")
        blocked = []
        
        # Use parallel processing for efficiency
        with ThreadPoolExecutor(max_workers=10) as executor:
            results = list(executor.map(check_url_content, urls))
            
            for i, (is_blocked, reason) in enumerate(results):
                url = urls[i]
                if is_blocked:
                    blocked.append(f"{url} - {reason}")
                    print(f"‚ùå BLOCKED: {url} - {reason}")
                else:
                    print(f"‚úÖ Clean: {url}")
        
        if blocked:
            if os.getenv('GITHUB_EVENT_NAME') == 'schedule':
                print(f"\nüö® SECURITY ALERT: {len(blocked)} compromised URLs found in repository!")
            else:
                print(f"\n‚ùå SECURITY CHECK FAILED: Inappropriate content detected!")
            for url in blocked:
                print(f"  - {url}")
            sys.exit(1)
        else:
            print(f"\n‚úÖ All {len(urls)} URLs passed security check")
            sys.exit(0)
        EOF
    
    - name: Revert Malicious Commit
      if: failure() && github.event_name == 'push'
      run: |
        echo "üîÑ Reverting commit with inappropriate content..."
        git config --global user.name "Security Bot"
        git config --global user.email "security-bot@github.com"
        
        # Revert the latest commit
        git revert HEAD --no-edit -m "üö® SECURITY: Auto-revert commit containing inappropriate URLs
        
        This commit was automatically reverted because it contained URLs with inappropriate content.
        The security scan detected violations of content policy.
        
        Original commit: ${{ github.sha }}
        Detected violations: See action logs for details
        
        Please remove the inappropriate URLs and recommit your changes."
        
        # Push the revert commit
        git push origin ${{ github.ref_name }}
        
        echo "‚úÖ Malicious commit reverted successfully"
    
    - name: Notify Slack on Security Failure
      if: failure()
      run: |
        # Determine if this was a revert action
        if [[ "${{ github.event_name }}" == "push" ]]; then
          ACTION_TYPE="üîÑ COMMIT REVERTED"
          MESSAGE="Inappropriate content was automatically reverted from the repository."
        else
          ACTION_TYPE="üö® SECURITY ALERT"
          MESSAGE="Inappropriate URLs detected during scheduled scan."
        fi
        
        curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
        -H "Content-Type: application/json" \
        --data "{
          \"Content\": \"$ACTION_TYPE\\nRepository: ${{ github.repository }}\\nBranch: ${{ github.ref_name }}\\nCommit: ${{ github.sha }}\\n\\n$MESSAGE\\n\\nAction: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\"
        }"
